---
layout: single
title: "A ConvNet for the 2020s(ConvNeXt)
"

excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-03-10
last_modified_at: 2025-03-10
classes: #wide    
---
[A ConvNet for the 2020s(ConvNeXt)](https://arxiv.org/pdf/2201.03545){: .btn .btn--primary}


# Abstract

&nbsp;&nbsp; visual recognition의 광란의 20년대는 **VIT**의 도입으로부터 시작되었다. 또한 VIT는 ConvNets을 제치고 빠른 시일 내에 SOTA를 달성했다. 그러나 VIT는 object detection, semantic segmentation과 같은 일반적인 vision task 적용에서 어려움을 직면했고, **hierarchical Transformer(Swin Transformer 등)** ConvNet의 기술을 다시 도입하여 transformer를 일반적인 vision backnorn network로 사용할 수 있게 만들었으며, 다양한 vision task에서 좋은 성능을 보였다. 이러한 하이브리드 접근의 효과는 여전히 convolution의 고유한 bias 편향보다는 transformer의 고유한 우수성에 크게 기여한다. 이 논문에서는 design space를 재검토하고,  <span style='color:red'>**순수한 ConvNet이 달성할 수 있는 한계를 테스트한다.** </span> Vision Transformer 설계를 위해 standard ResNet을 점진적으로 현대화하고, 이 과정에서 성능에 영향을 주는 몇가지 주요 구성 요소를 확인한다. **이 연구의 결과는 ConvNeXt라고 부른다.** 

# 1. Introduction

&nbsp;&nbsp; 2010년대를 돌아보면 십수년동안 주목할만한 deep learning의 발전이 있었고, vision에서의 주된 driver는 CNN이었다. 특히 2010년대 AlexNet의 도입은 새로운 computer vision의 시대를 열었다. 이 분야는 빠른 속도로 발전했고, VGGNet, Inceptions, ResNet, DensNet 등의 ConvNets의 출현은 정확도, 효율성 및 확장성, 많은 유용한 디자인 원칙을 대중화하였다. 
&nbsp;&nbsp; 이중 computer vision에서 ConvNets 주요 전략은 **Sliding window strategy(CNN)**이고 특히 high-resolution에서 좋은 성능을 보였다. 동일한 시기에 자연어 처리분야에서는 CV와 다르게 Transformer가 RNN을 대체하며 지배적인 backborn network로 자리잡고 있었다. language와 vision domain사이의서의 불일치에도 불구하고, 두 stream은 2020년대 vision transformer의 도입으로 융합되었다. 이미지를 초기에 분할하는 patch layer를 제외하면 VIT는 이미지별로 귀납적 bias를 일으키지 않고, 원래의 NLP Transformer에서 작은 변화를 준다. VIT의 주된 초점 중 하나는 Scaling behavior에 있다. 거대한 모델의 크기와 데이터셋 덕분에 Transformer는 ResNet보다 더 좋은 성능을 보일 수 있었다. 이러한 결과들은 Classification에서 좋은 결과를 보였지만, Computer vision은 Classification에만 국한되지 않는다. 과거 다양한 CV task의 해결법은 fully-convolution paradigm, Sliding-window에 의존하였다. ConvNet의 귀납적 bias가 없다면, ViT model은 일반적인 vision backborn으로 채택되기에는 많은 문제가 발생한다. 가장 큰 문제는 VIT의 global attention design이다. 이는 input size에 대해 2차적인 복잡성을 가지고 있다. 이러한 문제들로 인해 ImageNet Classification정도는 적용이 가능하겠지만, 고해상도 이미지에 대해서는 다루기 어려울 것이다.
&nbsp;&nbsp; Hierarchical Transformers는 이러한 gap을 메꾸기 위해 하이브리드 접근법을 사용하였다(ex. sliding window 전략 재도입). Swin Transformer는 이 방향으로 나아가는 모델로, Transformer가 일반적인 vision backborn으로 채택되어 classification을 넘어서 다양한 vision task에서 SOTA를 달성할 수 있음을 보였다. <span style='color:red'>**Swin의 성공과 급진적인 적용은 또한 Convolution의 본질이 무의미해지는 것이 아니고, 여전히 발전할 방향이 많다는 것을 나타낸다.**</span> (backborn에서 개선할 부분이 남아있다.)
&nbsp;&nbsp; 이러한 양상속에서 Transformer의 많은 이점은 초점을 backborn convolution으로 바꾸었다. 그러나 이 시도는 cost가 많이 발생한다. 단순하게 sliding window self attention을 구현하는 것은 비쌀 수 있고, cyclic shifting과 같은 발전된 방법을 사용하는 것은 optimize 속도가 빠를 수는 있지만 시스템은 더욱 정교해진다. 반면, ConvNet이 이미 필요한 많은 속성을 충족한다는 것은 아이러니하다. ConvNet이 힘을 잃고 있는 유일한 이유는 Transformer가 많은 vision task에서 이를 능가하기 때문이며, 성능차이는 Transformer의 뛰어난 Scaling behavior에서 나타나고, multi head attention이 핵심 요소이다.
&nbsp;&nbsp; <span style='color:red'>**최근 문헌에서는 system level을 비교할 때 일반적으로 Swin과 ResNet이 선택된다.** (두 모델이 비슷한듯 다르며, 성능 차이가 발생)</span> ConvNets과 Swin은 similar inductive bias를 사용한다는 점이 유사하지만, training 과정이 다르고, macro/micro-level architecture design이 다르다. 논문에서는 이 두 모델에서 구분될만한 구조의 차이를 연구하고, network의 성능을 비교한다. 이 연구는 ConvNets의 VIT 이전과 이후 시대의 격차를 해소하고, ConvNet이 달성할 수 있는 한계를 테스트하기 위함이다. 
&nbsp;&nbsp; 이것을 수행하기 위해서 논문에서는 Standard ResNet을 향상된 방법으로 학습시켰고, 점진적으로 hierarchical vision Transformer의 구조를 현대화 시켰다. 연구에서의 키는 Transformer의 design이 ConvNet의 성능에 얼마나 영향을 미치는지이다. 이러한 초점에서 성능 차이에 기여하는 핵심 요소들을 발견하였다. 결과적으로 이것을 ConvNeXt라는 이름으로 제안하였고, Image Classification, Object Dectection, Semantic Segmentation 등 다양한 task에 적용시켰고, 놀랍게도 많은 benchmark에서 transformer와 경쟁할 수 있는 성능을 갖추었다.

# 2. Modernizing a ConvNet: a Roadmap
![Image5](/assets/images/Convnext/image1.jpg){: .align-center}
&nbsp;&nbsp; 이 챕터에서는 ResNet에서 ConvNet으로 이동하는 길을 알려주며, Transformer와 유사하다. FLOPs에 따른 두가지 모델 size를 고려한다. 논문에서는 간단하게 첫 번째 경우의 복잡성을 제시한다.

1. ResNet-50/Swin-T 체제 : $4.5 \times 10^9$ FLOPs (: 컴퓨팅 성능의 단위)
2. ResNet-200/Swin-B 체제 : $15.0 \times 10^9$ FLOPs

&nbsp;&nbsp; High-level에서 이 연구는 ConvNet으로서의 네트워크 단순성을 유지하면서 Swin과 다른 수준의 설계를 조사하고 따르는 것을 목표로 한다. 로드맵은 다음과 같다.

1. Starting point : ResNet-50
2. VIT와 유사한 방법으로 훈련시켜 기존 ResNet-50보다 향상된 성능을 얻음(baseline)
3. macro design, ResNeXt, inverted bottleneck, large kernel size, various layer-wise micro design에 대해 연구

&nbsp;&nbsp; 위 그림에서 과정의 결과가 나타나며, network modernization 각 스텝에서 결과를 도출했다. 네트워크 복잡도가 최종 성능과 관련이 있기 때문에, FLOPs는 대략적으로 제어되지만 중간에서는 FLOPs가 기준 모델과 다를 수 있다. 모든 실험은 ImageNet-1K로 진행되었다.

![Image5](/assets/images/Convnext/image2.jpg){: .align-center}
위 그림은 각 단계에 대한 성능표이다. 다음 과정들에 대해 알아보자.

## 2.1 Training Techniques


