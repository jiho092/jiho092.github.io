---
layout: single
title: "A ConvNet for the 2020s(ConvNeXt)
"

excerpt : ""
categories: 
    - deeplearningCV #ì¹´í…Œê³ ë¦¬ì„¤ì •
tag: 
    - [] #í…Œê·¸

date: 2025-03-10
last_modified_at: 2025-03-10
classes: #wide    
---
[A ConvNet for the 2020s(ConvNeXt)](https://arxiv.org/pdf/2201.03545){: .btn .btn--primary}


# Abstract

&nbsp;&nbsp; visual recognitionì˜ ê´‘ë€ì˜ 20ë…„ëŒ€ëŠ” **VIT**ì˜ ë„ì…ìœ¼ë¡œë¶€í„° ì‹œì‘ë˜ì—ˆë‹¤. ë˜í•œ VITëŠ” ConvNetsì„ ì œì¹˜ê³  ë¹ ë¥¸ ì‹œì¼ ë‚´ì— SOTAë¥¼ ë‹¬ì„±í–ˆë‹¤. ê·¸ëŸ¬ë‚˜ VITëŠ” object detection, semantic segmentationê³¼ ê°™ì€ ì¼ë°˜ì ì¸ vision task ì ìš©ì—ì„œ ì–´ë ¤ì›€ì„ ì§ë©´í–ˆê³ , **hierarchical Transformer(Swin Transformer ë“±)** ConvNetì˜ ê¸°ìˆ ì„ ë‹¤ì‹œ ë„ì…í•˜ì—¬ transformerë¥¼ ì¼ë°˜ì ì¸ vision backnorn networkë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì—ˆìœ¼ë©°, ë‹¤ì–‘í•œ vision taskì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. ì´ëŸ¬í•œ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ì˜ íš¨ê³¼ëŠ” ì—¬ì „íˆ convolutionì˜ ê³ ìœ í•œ bias í¸í–¥ë³´ë‹¤ëŠ” transformerì˜ ê³ ìœ í•œ ìš°ìˆ˜ì„±ì— í¬ê²Œ ê¸°ì—¬í•œë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” design spaceë¥¼ ì¬ê²€í† í•˜ê³ ,  <span style='color:red'>**ìˆœìˆ˜í•œ ConvNetì´ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” í•œê³„ë¥¼ í…ŒìŠ¤íŠ¸í•œë‹¤.** </span> Vision Transformer ì„¤ê³„ë¥¼ ìœ„í•´ standard ResNetì„ ì ì§„ì ìœ¼ë¡œ í˜„ëŒ€í™”í•˜ê³ , ì´ ê³¼ì •ì—ì„œ ì„±ëŠ¥ì— ì˜í–¥ì„ ì£¼ëŠ” ëª‡ê°€ì§€ ì£¼ìš” êµ¬ì„± ìš”ì†Œë¥¼ í™•ì¸í•œë‹¤. **ì´ ì—°êµ¬ì˜ ê²°ê³¼ëŠ” ConvNeXtë¼ê³  ë¶€ë¥¸ë‹¤.** 

# 1. Introduction

&nbsp;&nbsp; 2010ë…„ëŒ€ë¥¼ ëŒì•„ë³´ë©´ ì‹­ìˆ˜ë…„ë™ì•ˆ ì£¼ëª©í• ë§Œí•œ deep learningì˜ ë°œì „ì´ ìˆì—ˆê³ , visionì—ì„œì˜ ì£¼ëœ driverëŠ” CNNì´ì—ˆë‹¤. íŠ¹íˆ 2010ë…„ëŒ€ AlexNetì˜ ë„ì…ì€ ìƒˆë¡œìš´ computer visionì˜ ì‹œëŒ€ë¥¼ ì—´ì—ˆë‹¤. ì´ ë¶„ì•¼ëŠ” ë¹ ë¥¸ ì†ë„ë¡œ ë°œì „í–ˆê³ , VGGNet, Inceptions, ResNet, DensNet ë“±ì˜ ConvNetsì˜ ì¶œí˜„ì€ ì •í™•ë„, íš¨ìœ¨ì„± ë° í™•ì¥ì„±, ë§ì€ ìœ ìš©í•œ ë””ìì¸ ì›ì¹™ì„ ëŒ€ì¤‘í™”í•˜ì˜€ë‹¤. 
&nbsp;&nbsp; ì´ì¤‘ computer visionì—ì„œ ConvNets ì£¼ìš” ì „ëµì€ **Sliding window strategy(CNN)**ì´ê³  íŠ¹íˆ high-resolutionì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. ë™ì¼í•œ ì‹œê¸°ì— ìì—°ì–´ ì²˜ë¦¬ë¶„ì•¼ì—ì„œëŠ” CVì™€ ë‹¤ë¥´ê²Œ Transformerê°€ RNNì„ ëŒ€ì²´í•˜ë©° ì§€ë°°ì ì¸ backborn networkë¡œ ìë¦¬ì¡ê³  ìˆì—ˆë‹¤. languageì™€ vision domainì‚¬ì´ì˜ì„œì˜ ë¶ˆì¼ì¹˜ì—ë„ ë¶ˆêµ¬í•˜ê³ , ë‘ streamì€ 2020ë…„ëŒ€ vision transformerì˜ ë„ì…ìœ¼ë¡œ ìœµí•©ë˜ì—ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ì´ˆê¸°ì— ë¶„í• í•˜ëŠ” patch layerë¥¼ ì œì™¸í•˜ë©´ VITëŠ” ì´ë¯¸ì§€ë³„ë¡œ ê·€ë‚©ì  biasë¥¼ ì¼ìœ¼í‚¤ì§€ ì•Šê³ , ì›ë˜ì˜ NLP Transformerì—ì„œ ì‘ì€ ë³€í™”ë¥¼ ì¤€ë‹¤. VITì˜ ì£¼ëœ ì´ˆì  ì¤‘ í•˜ë‚˜ëŠ” Scaling behaviorì— ìˆë‹¤. ê±°ëŒ€í•œ ëª¨ë¸ì˜ í¬ê¸°ì™€ ë°ì´í„°ì…‹ ë•ë¶„ì— TransformerëŠ” ResNetë³´ë‹¤ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆì—ˆë‹¤. ì´ëŸ¬í•œ ê²°ê³¼ë“¤ì€ Classificationì—ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì˜€ì§€ë§Œ, Computer visionì€ Classificationì—ë§Œ êµ­í•œë˜ì§€ ì•ŠëŠ”ë‹¤. ê³¼ê±° ë‹¤ì–‘í•œ CV taskì˜ í•´ê²°ë²•ì€ fully-convolution paradigm, Sliding-windowì— ì˜ì¡´í•˜ì˜€ë‹¤. ConvNetì˜ ê·€ë‚©ì  biasê°€ ì—†ë‹¤ë©´, ViT modelì€ ì¼ë°˜ì ì¸ vision backbornìœ¼ë¡œ ì±„íƒë˜ê¸°ì—ëŠ” ë§ì€ ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ê°€ì¥ í° ë¬¸ì œëŠ” VITì˜ global attention designì´ë‹¤. ì´ëŠ” input sizeì— ëŒ€í•´ 2ì°¨ì ì¸ ë³µì¡ì„±ì„ ê°€ì§€ê³  ìˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë“¤ë¡œ ì¸í•´ ImageNet Classificationì •ë„ëŠ” ì ìš©ì´ ê°€ëŠ¥í•˜ê² ì§€ë§Œ, ê³ í•´ìƒë„ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œëŠ” ë‹¤ë£¨ê¸° ì–´ë ¤ìš¸ ê²ƒì´ë‹¤.
&nbsp;&nbsp; Hierarchical TransformersëŠ” ì´ëŸ¬í•œ gapì„ ë©”ê¾¸ê¸° ìœ„í•´ í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•˜ì˜€ë‹¤(ex. sliding window ì „ëµ ì¬ë„ì…). Swin TransformerëŠ” ì´ ë°©í–¥ìœ¼ë¡œ ë‚˜ì•„ê°€ëŠ” ëª¨ë¸ë¡œ, Transformerê°€ ì¼ë°˜ì ì¸ vision backbornìœ¼ë¡œ ì±„íƒë˜ì–´ classificationì„ ë„˜ì–´ì„œ ë‹¤ì–‘í•œ vision taskì—ì„œ SOTAë¥¼ ë‹¬ì„±í•  ìˆ˜ ìˆìŒì„ ë³´ì˜€ë‹¤. <span style='color:red'>**Swinì˜ ì„±ê³µê³¼ ê¸‰ì§„ì ì¸ ì ìš©ì€ ë˜í•œ Convolutionì˜ ë³¸ì§ˆì´ ë¬´ì˜ë¯¸í•´ì§€ëŠ” ê²ƒì´ ì•„ë‹ˆê³ , ì—¬ì „íˆ ë°œì „í•  ë°©í–¥ì´ ë§ë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ë‚¸ë‹¤.**</span> (backbornì—ì„œ ê°œì„ í•  ë¶€ë¶„ì´ ë‚¨ì•„ìˆë‹¤.)
&nbsp;&nbsp; ì´ëŸ¬í•œ ì–‘ìƒì†ì—ì„œ Transformerì˜ ë§ì€ ì´ì ì€ ì´ˆì ì„ backborn convolutionìœ¼ë¡œ ë°”ê¾¸ì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì‹œë„ëŠ” costê°€ ë§ì´ ë°œìƒí•œë‹¤. ë‹¨ìˆœí•˜ê²Œ sliding window self attentionì„ êµ¬í˜„í•˜ëŠ” ê²ƒì€ ë¹„ìŒ€ ìˆ˜ ìˆê³ , cyclic shiftingê³¼ ê°™ì€ ë°œì „ëœ ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ optimize ì†ë„ê°€ ë¹ ë¥¼ ìˆ˜ëŠ” ìˆì§€ë§Œ ì‹œìŠ¤í…œì€ ë”ìš± ì •êµí•´ì§„ë‹¤. ë°˜ë©´, ConvNetì´ ì´ë¯¸ í•„ìš”í•œ ë§ì€ ì†ì„±ì„ ì¶©ì¡±í•œë‹¤ëŠ” ê²ƒì€ ì•„ì´ëŸ¬ë‹ˆí•˜ë‹¤. ConvNetì´ í˜ì„ ìƒê³  ìˆëŠ” ìœ ì¼í•œ ì´ìœ ëŠ” Transformerê°€ ë§ì€ vision taskì—ì„œ ì´ë¥¼ ëŠ¥ê°€í•˜ê¸° ë•Œë¬¸ì´ë©°, ì„±ëŠ¥ì°¨ì´ëŠ” Transformerì˜ ë›°ì–´ë‚œ Scaling behaviorì—ì„œ ë‚˜íƒ€ë‚˜ê³ , multi head attentionì´ í•µì‹¬ ìš”ì†Œì´ë‹¤.
&nbsp;&nbsp; <span style='color:red'>**ìµœê·¼ ë¬¸í—Œì—ì„œëŠ” system levelì„ ë¹„êµí•  ë•Œ ì¼ë°˜ì ìœ¼ë¡œ Swinê³¼ ResNetì´ ì„ íƒëœë‹¤.** (ë‘ ëª¨ë¸ì´ ë¹„ìŠ·í•œë“¯ ë‹¤ë¥´ë©°, ì„±ëŠ¥ ì°¨ì´ê°€ ë°œìƒ)</span> ConvNetsê³¼ Swinì€ similar inductive biasë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ì ì´ ìœ ì‚¬í•˜ì§€ë§Œ, training ê³¼ì •ì´ ë‹¤ë¥´ê³ , macro/micro-level architecture designì´ ë‹¤ë¥´ë‹¤. ë…¼ë¬¸ì—ì„œëŠ” ì´ ë‘ ëª¨ë¸ì—ì„œ êµ¬ë¶„ë ë§Œí•œ êµ¬ì¡°ì˜ ì°¨ì´ë¥¼ ì—°êµ¬í•˜ê³ , networkì˜ ì„±ëŠ¥ì„ ë¹„êµí•œë‹¤. ì´ ì—°êµ¬ëŠ” ConvNetsì˜ VIT ì´ì „ê³¼ ì´í›„ ì‹œëŒ€ì˜ ê²©ì°¨ë¥¼ í•´ì†Œí•˜ê³ , ConvNetì´ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” í•œê³„ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•¨ì´ë‹¤. 
&nbsp;&nbsp; ì´ê²ƒì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ì„œ ë…¼ë¬¸ì—ì„œëŠ” Standard ResNetì„ í–¥ìƒëœ ë°©ë²•ìœ¼ë¡œ í•™ìŠµì‹œì¼°ê³ , ì ì§„ì ìœ¼ë¡œ hierarchical vision Transformerì˜ êµ¬ì¡°ë¥¼ í˜„ëŒ€í™” ì‹œì¼°ë‹¤. ì—°êµ¬ì—ì„œì˜ í‚¤ëŠ” Transformerì˜ designì´ ConvNetì˜ ì„±ëŠ¥ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ì´ë‹¤. ì´ëŸ¬í•œ ì´ˆì ì—ì„œ ì„±ëŠ¥ ì°¨ì´ì— ê¸°ì—¬í•˜ëŠ” í•µì‹¬ ìš”ì†Œë“¤ì„ ë°œê²¬í•˜ì˜€ë‹¤. ê²°ê³¼ì ìœ¼ë¡œ ì´ê²ƒì„ ConvNeXtë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì œì•ˆí•˜ì˜€ê³ , Image Classification, Object Dectection, Semantic Segmentation ë“± ë‹¤ì–‘í•œ taskì— ì ìš©ì‹œì¼°ê³ , ë†€ëê²Œë„ ë§ì€ benchmarkì—ì„œ transformerì™€ ê²½ìŸí•  ìˆ˜ ìˆëŠ” ì„±ëŠ¥ì„ ê°–ì¶”ì—ˆë‹¤.

# 2. Modernizing a ConvNet: a Roadmap
![Image5](/assets/images/Convnext/image1.jpg){: .align-center}
&nbsp;&nbsp; ì´ ì±•í„°ì—ì„œëŠ” ResNetì—ì„œ ConvNetìœ¼ë¡œ ì´ë™í•˜ëŠ” ê¸¸ì„ ì•Œë ¤ì£¼ë©°, Transformerì™€ ìœ ì‚¬í•˜ë‹¤. FLOPsì— ë”°ë¥¸ ë‘ê°€ì§€ ëª¨ë¸ sizeë¥¼ ê³ ë ¤í•œë‹¤. ë…¼ë¬¸ì—ì„œëŠ” ê°„ë‹¨í•˜ê²Œ ì²« ë²ˆì§¸ ê²½ìš°ì˜ ë³µì¡ì„±ì„ ì œì‹œí•œë‹¤.

1. ResNet-50/Swin-T ì²´ì œ : $4.5 \times 10^9$ FLOPs (: ì»´í“¨íŒ… ì„±ëŠ¥ì˜ ë‹¨ìœ„)
2. ResNet-200/Swin-B ì²´ì œ : $15.0 \times 10^9$ FLOPs

&nbsp;&nbsp; High-levelì—ì„œ ì´ ì—°êµ¬ëŠ” ConvNetìœ¼ë¡œì„œì˜ ë„¤íŠ¸ì›Œí¬ ë‹¨ìˆœì„±ì„ ìœ ì§€í•˜ë©´ì„œ Swinê³¼ ë‹¤ë¥¸ ìˆ˜ì¤€ì˜ ì„¤ê³„ë¥¼ ì¡°ì‚¬í•˜ê³  ë”°ë¥´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•œë‹¤. ë¡œë“œë§µì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

1. Starting point : ResNet-50
2. VITì™€ ìœ ì‚¬í•œ ë°©ë²•ìœ¼ë¡œ í›ˆë ¨ì‹œì¼œ ê¸°ì¡´ ResNet-50ë³´ë‹¤ í–¥ìƒëœ ì„±ëŠ¥ì„ ì–»ìŒ(baseline)
3. macro design, ResNeXt, inverted bottleneck, large kernel size, various layer-wise micro designì— ëŒ€í•´ ì—°êµ¬

&nbsp;&nbsp; ìœ„ ê·¸ë¦¼ì—ì„œ ê³¼ì •ì˜ ê²°ê³¼ê°€ ë‚˜íƒ€ë‚˜ë©°, network modernization ê° ìŠ¤í…ì—ì„œ ê²°ê³¼ë¥¼ ë„ì¶œí–ˆë‹¤. ë„¤íŠ¸ì›Œí¬ ë³µì¡ë„ê°€ ìµœì¢… ì„±ëŠ¥ê³¼ ê´€ë ¨ì´ ìˆê¸° ë•Œë¬¸ì—, FLOPsëŠ” ëŒ€ëµì ìœ¼ë¡œ ì œì–´ë˜ì§€ë§Œ ì¤‘ê°„ì—ì„œëŠ” FLOPsê°€ ê¸°ì¤€ ëª¨ë¸ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤. ëª¨ë“  ì‹¤í—˜ì€ ImageNet-1Kë¡œ ì§„í–‰ë˜ì—ˆë‹¤.

![Image5](/assets/images/Convnext/image2.jpg){: .align-center}
ìœ„ ê·¸ë¦¼ì€ ê° ë‹¨ê³„ì— ëŒ€í•œ ì„±ëŠ¥í‘œì´ë‹¤. ë‹¤ìŒ ê³¼ì •ë“¤ì— ëŒ€í•´ ì•Œì•„ë³´ì.

## 2.1 Training Techniques

**ResNet-50(enhanced recipe)** (<span style='color:red'>**78.8%**</span>)

&nbsp;&nbsp; ìµœì‹  ë°©ë²•(VIT)ì™€ ë™ì¼í•œ í•™ìŠµ ë°©ë²•ì„ ì‚¬ìš©í•œë‹¤.

1. AdamW ì‚¬ìš©
2. DeiTì™€ ê°€ê¹Œìš´ Hyper parameterë¥¼ ì‚¬ìš©
3. Data Augmentation (Mixup, Cutmix, RandAugment, Random Erasing ...)



## 2.2 Macro Design

&nbsp;&nbsp; Swin Transformersì˜ macro networkì— ëŒ€í•´ ë¶„ì„í•œë‹¤. Swinì€ ConvNetsê³¼ ê°™ì€ multi-stage designì„ ì‚¬ìš©í•˜ë©° ê° ë‹¨ê³„ë§ˆë‹¤ feature mapì˜ í¬ê¸°ê°€ ë‹¤ë¥´ë‹¤. ì—¬ê¸°ì„œ ê³ ë ¤í•  ì‚¬í•­ì€ ë‘ê°€ì§€ê°€ ìˆë‹¤.

1. Changing stage compute ratio **stage ratio**

- RestNet-50ì˜ block ìˆ˜ë¥¼  (3,4,6,3)ì—ì„œ (3,3,9,3)ìœ¼ë¡œ ë°”ê¾¸ì–´ Swinê³¼ ê°™ì€ ë¹„ìœ¨ë¡œ ë§Œë“¦(<span style='color:red'>**79.4%**</span>)

2. Changing stem to "patchify" **'patchify' stem**

- ResNetì—ì„œëŠ” $7 \times 7$ conv. layerì™€ stride : 2, max poolingì„ ì‚¬ìš©í•˜ëŠ”ë°, Swinì˜ Patchifyì²˜ëŸ¼ patch sizeì™€ ë¹„ìŠ·í•˜ê²Œ $7 \times 7 \to 4 \times 4$ë¡œ ë³€ê²½í•˜ê³  strideë¥¼ $2 \to 4$ë¡œ ë³€ê²½ (<span style='color:red'>**79.5%**</span>)


## 2.3 ResNeXt-ify
![Image5](/assets/images/Convnext/image5.jpg){: .align-center}
&nbsp;&nbsp; ì—¬ê¸°ì„œëŠ” ResNeXtì˜ ì•„ì´ë””ì–´ë¥¼ ì ìš©í•œë‹¤(ê¸°ì¡´ ResNetë³´ë‹¤ FLOPs/Accuracyì—ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„). **ResNeXtì˜ í•µì‹¬ì€ Group Convolutionì´ë‹¤.(ë‹¤ë¥¸ Groupê³¼ convolution filterê°€ ë¶„ë¦¬ë¨)** 
![Image5](/assets/images/Convnext/image3.jpg){: .align-center}

&nbsp;&nbsp; ë…¼ë¬¸ì˜ ì—°êµ¬ì—ì„œëŠ” depthwise convolutionì„ ì‚¬ìš©í•œë‹¤. ì´ ë°©ë²•ì´ Self Attentionì—ì„œ weighted sumê³¼ ë¹„ìŠ·í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ë˜í•œdepthwise convolution í›„ $1 \times 1$ Conv.ê°€ ì±„ë„ë³„ ì •ë³´ë¥¼ ì„ë„ë¡ ë„ì™€ì¤€ë‹¤. depthwiseë¥¼ ì‚¬ìš©í•˜ë©´ì„œ ì—°ì‚°ìˆ˜ê°€ ì¤„ì—ˆì§€ë§Œ ì •í™•ë„ëŠ” ìœ ì§€í•˜ì˜€ê³ , ì—°ì‚°ëŸ‰ì˜ ê°ì†Œë¡œ ì±„ë„ì˜ ìˆ˜ë¥¼ ì¦ê°€(64 to 96)ì‹œì¼°ë‹¤.
![Image5](/assets/images/Convnext/image4.jpg){: .align-center}
(<span style='color:red'>**80.5%**</span>)


## 2.4 inverted Bottleneck

&nbsp;&nbsp; Transformerì—ì„œ ì¤‘ìš”í•œ ë””ìì¸ì€ Inverted bottleneckì´ë‹¤. ì´ê²ƒì€ MLP blackì„ input sizeì˜ 4ë°°ë¡œ ë§Œë“œëŠ” ê²ƒì¸ë°, ì´ êµ¬ì¡°ë¥¼ ì´ìš©í•œë‹¤. ì´ ê²½ìš° $1 \times 1$ shortcut conv. layerë¡œ ì¸í•´ ì±„ë„ ìˆ˜ê°€ ê°ì†Œí•˜ì—¬ FLOPsì€ ì¤„ì–´ë“ ë‹¤.
(<span style='color:red'>**80.6%**</span>)

## 2.5 Large Kernel Size

&nbsp;&nbsp; CNNì—ì„œëŠ” ì¼ë°˜ì ìœ¼ë¡œ $3 \times 3$ kernelì„ ì‚¬ìš©í•˜ëŠ”ë°, GPU ì„±ëŠ¥ì´ ë°œì „í•˜ë©´ì„œ Vision Transformerì—ì„œëŠ” ìµœì†Œ $7 \times 7$ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ì ìš©í•´ë³¸ë‹¤. ì²« ë‹¨ê³„ë¡œ depthwise conv.ì˜ ìœ„ì¹˜ë¥¼ Transformerì²˜ëŸ¼ ì˜¬ë¦¬ëŠ” ê²ƒì¸ë°, $3 \times 3$ìœ¼ë¡œ FLOPsì´ ê°ì†Œí•˜ì§€ë§Œ ì ìš©ì‹œ ì„±ëŠ¥ì´ **79.9%**
ë¡œ ê°ì†Œí•œë‹¤. kernel sizeë¥¼ $7 \times 7$ë¡œ ì ìš©ì‹œ ì„±ëŠ¥ì´ ë‹¤ì‹œ ìƒìŠ¹í•œë‹¤.
(<span style='color:red'>**80.6%**</span>)

## 2.6 Micro Design
&nbsp;&nbsp; ì´ ì„¹ì…˜ì—ì„œëŠ” micro scaleì—ì„œ ì°¨ì´ë¥¼ í™•ì¸í•œë‹¤. ëŒ€ë¶€ë¶„ì€ layer ìˆ˜ì¤€ì—ì„œ ì´ë£¨ì–´ì§„ë‹¤.

![Image5](/assets/images/Convnext/image6.jpg){: .align-center}

* Fewer activation function
&nbsp;&nbsp; NLPì™€ visionì—ì„œ êµ¬ì¡° ì°¨ì´ì¤‘ í•œê°€ì§€ëŠ” activation functionì´ë‹¤. ì—¬ê¸°ì—ì„œëŠ” activation functionì„ ReLUì—ì„œ GELUë¡œ ë³€ê²½ì‹œí‚¨ë‹¤.(Swinì´ GELU ì‚¬ìš©)
&nbsp;&nbsp; ìœ„ ê·¸ë¦¼ì„ ë³´ë©´ Transformerì—ëŠ” MLPì— activationì´ í•˜ë‚˜ë§Œ ì¡´ì¬í•˜ëŠ” ë°˜ë©´ ResNetì—ì„œëŠ” normalization, activationì´ ê° layerë§ˆë‹¤ ì¡´ì¬í•˜ì—¬ ì´ë¥¼ ì œê±°í•œë‹¤. ì´ ë•Œë¶€í„° ì„±ëŠ¥ì´ Swin-Tì™€ ë¹„ìŠ·í•œ ê²°ê³¼ë¥¼ ë³´ì¸ë‹¤.

(<span style='color:red'>**81.3%**</span>)

* Fewer normalization layers

&nbsp;&nbsp; TransformerëŠ” MSA, MLP block ì•ì—ì„œ normalizationì„ ì§„í–‰í•˜ì—¬ ì´ êµ¬ì¡°ë¥¼ ConvNextì—ë„ ì ìš©ì‹œí‚¨ë‹¤.
(<span style='color:red'>**81.4%**</span>)

* Substituting BN with LN

&nbsp;&nbsp; Vision taskì—ì„œëŠ” Batch Normalization(BL)ì„ ì£¼ë¡œ ì‚¬ìš©í•´ì™”ë‹¤. ê·¸ëŸ¬ë‚˜ NLPì—ì„œëŠ” Layer Normalization(LN)ì„ ë§ì´ ì‚¬ìš©í•œë‹¤. ì´ë¥¼ ì ìš©í•˜ë©´ ê¸°ì¡´ ResNetì—ì„œëŠ” ì„±ëŠ¥ì´ ì•½ê°„ ê°ì†Œí•˜ì§€ë§Œ, ConvNeXtì—ì„œëŠ” ì„±ëŠ¥ì´ í–¥ìƒë˜ì—ˆë‹¤.

(<span style='color:red'>**81.5%**</span>)

* Separate downsampling layer

&nbsp;&nbsp; ResNetì—ì„œëŠ” ê° ë‹¨ê²Œì˜ ì‹œì‘ì¸ residual blockì—ì„œ downsamplingì´ ì§„í–‰ë˜ëŠ”ë° ì´ë•Œ $3 \times 3, stride : 2$ë¥¼ ì‚¬ìš©í•œë‹¤. Swinì—ì„œëŠ” layerë“¤ ì‚¬ì´ì— ê·¼ì²˜ windowë¥¼ í•©ì¹˜ë©° ì‚¬ìš©í•˜ëŠ”ë°, ì´ ê²ƒê³¼ ë¹„ìŠ·í•˜ê²Œ $2 \times 2$ conv.ë¥¼ ì‚¬ìš©í•œë‹¤.
(<span style='color:red'>**82.0%**</span>)

# 3. Empirical Evaluation on ImageNet

&nbsp;&nbsp; ì•ì„  ì—°êµ¬ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ResNet-50/200ì„ í˜„ëŒ€í™” ì‹œì¼œ ConvNeXt-T/S/B/L/XLì„ ë§Œë“¤ì—ˆë‹¤. ê° ìŠ¤í…Œì´ì§€ì˜ ì±„ë„ê³¼ ë¸”ë½ ìˆ˜ë¥¼ ì •ë¦¬í•œ í‘œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.


![Image5](/assets/images/Convnext/image7.jpg){: .align-center}

ë˜í•œ ì´ì „ ëª¨ë¸ë“¤ê³¼ì˜ êµ¬ì¡° ì°¨ì´ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.
![Image5](/assets/images/Convnext/image8.jpg){: .align-center}

# 4. ConvNeXt ë…¼ë¬¸ì˜ ì‹¤í—˜ ì„¸íŒ… ì •ë¦¬

**ResNetê³¼ Swin Transformerì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ë©° ConvNeXtì˜ ìš°ìˆ˜ì„±ì„ ì…ì¦**í–ˆë‹¤.  
ë‹¤ìŒì€ ë…¼ë¬¸ì—ì„œ ì‚¬ìš©í•œ ì‹¤í—˜ ì…‹íŒ…ì´ë‹¤.

---

## 1. ëª©ì 
1. **ResNet ëŒ€ë¹„ ConvNeXt ì„±ëŠ¥ ë¹„êµ**
2. **Swin Transformer ëŒ€ë¹„ ConvNeXt ì„±ëŠ¥ ë¹„êµ**
3. **Downstream task(Detection, Segmentation)ì—ì„œ ConvNeXtì˜ ì„±ëŠ¥ í‰ê°€**

---

## 2. ëª¨ë¸ êµ¬ì„±
###  ConvNeXt ì£¼ìš” íŠ¹ì§•
- **Depthwise Convolution**
- **LayerNorm**
- **MLP ë¸”ë¡ í™œìš© (ReLU â†’ GELU)**
- **ResNetê³¼ Swin Transformerì˜ ì¥ì  ê²°í•©**

###  ConvNeXt ëª¨ë¸ êµ¬ì¡°
| ëª¨ë¸ | Depths | Channels |
|------|--------|---------|
| ConvNeXt-Tiny | [3, 3, 9, 3] | [96, 192, 384, 768] |
| ConvNeXt-Small | [3, 3, 27, 3] | [96, 192, 384, 768] |
| ConvNeXt-Base | [3, 3, 27, 3] | [128, 256, 512, 1024] |
| ConvNeXt-Large | [3, 3, 27, 3] | [192, 384, 768, 1536] |
| ConvNeXt-XL | [3, 3, 27, 3] | [256, 512, 1024, 2048] |

---

## 3. Classification (ImageNet-1K)
| ì„¤ì • í•­ëª© | ê°’ |
|-----------|-----------|
| **ë°ì´í„°ì…‹** | ImageNet-1K |
| **Input Image Size** | 224x224 |
| **Optimizer** | AdamW |
| **Learning Rate (LR)** | 4e-3 (Cosine Decay) |
| **Batch Size** | 4096 |
| **Weight Decay** | 0.05 |
| **Epochs** | 300 |
| **Augmentation** | RandAugment, Mixup, CutMix |
| **Regularization** | Label Smoothing (0.1), DropPath (0.1 ~ 0.4) |

---

## 4. Object Detection (COCO)
- **Backbone:** ConvNeXt-Base, Large, XLarge  
- **Detection Framework:** Mask R-CNN, Cascade Mask R-CNN  
- **Training Schedule:** 1x (12 epochs) & 3x (36 epochs)  
- **Optimizer:** AdamW, LR = 1e-4  
- **Augmentation:** Multi-scale Training, Large Scale Jittering  

---

## 5. Semantic Segmentation (ADE20K)
- **Backbone:** ConvNeXt-Base, Large, XLarge  
- **Decoder:** UPerNet (Unified Perceptual Parsing Network)  
- **Input Image Size:** 512x512  
- **Optimizer:** AdamW, LR = 6e-5  
- **Batch Size:** 16  
- **Epochs:** 160K Iterations (~160 epochs)  
- **Augmentation:** Multi-scale Training, Random Crop  

---

## ğŸ”¹ 6ï¸âƒ£ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½
### ğŸŸ¢ ImageNet-1K ë¶„ë¥˜ ì„±ëŠ¥
- ConvNeXt-Tiny **82.1% Top-1 Accuracy** (ResNetë³´ë‹¤ +3% í–¥ìƒ)
- ConvNeXt-Large **85.8% Top-1 Accuracy** (Swin Transformer-Lê³¼ ë¹„ìŠ·í•œ ì„±ëŠ¥)

### ğŸŸ¢ Object Detection ì„±ëŠ¥ (COCO)
- ConvNeXt-Base + Mask R-CNN: **49.1 mAP**
- ConvNeXt-Large + Cascade Mask R-CNN: **53.2 mAP**  
- Swin Transformerë³´ë‹¤ ë¹ ë¥´ê³  ì„±ëŠ¥ì´ ë¹„ìŠ·  

### ğŸŸ¢ Semantic Segmentation ì„±ëŠ¥ (ADE20K)
- ConvNeXt-Base + UPerNet: **47.2 mIoU**  
- ConvNeXt-Large + UPerNet: **49.5 mIoU**  
- Swin-Lê³¼ ë™ë“±í•œ ì„±ëŠ¥  

---



# Conclusion

&nbsp;&nbsp; 2020ë…„ëŒ€ì— VITëŠ” ConvNetì„ ë°€ì–´ë‚´ë©° ìë¦¬ë¥¼ ì°¨ì§€í•˜ì˜€ë‹¤. ê·¸ëŸ¬ë‚˜ ConvNetì´ ë¶€ì¡±í•œ ê²ƒì´ ì•„ë‹ˆë¼ íƒêµ¬ê°€ ëœ ëœ ê²ƒì´ì—ˆë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” ConvNetì„ í˜„ëŒ€í™”í•œ ConvNeXtë¥¼ ì œì•ˆí•˜ì˜€ìœ¼ë©°, Swinë³´ë‹¤ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. ì´ë¡œì¸í•´ CNN ëª¨ë¸ì€ ì—¬ì „íˆ ê²½ìŸë ¥ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤.