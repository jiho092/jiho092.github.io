---
layout: single
title: "Night-to-Day Translation via Illumination Degradation Disentanglement(N2D3, 2024)"


excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-04-21
last_modified_at: 2025-04-21
classes: #wide    
---
[Night-to-Day Translation via Illumination Degradation Disentanglement](https://arxiv.org/pdf/2411.14504){: .btn .btn--primary}


# Abstract

&nbsp;&nbsp;Night to Day translation은 야간 이미지를 주간 이미지로 바꾸는 것에 초점을 둔다. 기존의 변환 방법에서는 semantic 정보를 보존하면서, day-domain 정보를 복원하였는데, 이 것은 degradation이 다른 pixel과 균일하게 완화되기 때문에, 성능을 향상시키는데 부적절하다는 것이 입증 되었다. 

&nbsp;&nbsp;따라서 논문에서는 **N2D3(Night-to-Day via Degradation Disentanglement)**방법을 제안한다. 이방법은 degradation pattern을 식별하기 위해 **Degradation disentanglement module**과 **Degradation-aware contrastive learning module**로 구성된다. 

&nbsp;&nbsp;이 것은 **Kubelka-Munk Theory**에 기반하여 photometic model로 부터 physical priors를 추출하고, illumination degradation regions을 구분하기 위해 disentanglement module을 설계한다. 이후 degradation-aware contrastive learning 전략을 사용하여, 서로 다른 degradation region에 대해 semantic consistency를 유지한다.

# 1. Introduction

&nbsp;&nbsp;야간 이미지는 Computer vision에서 탐지하기 어려운 경향이 있으며, 이에 관련하여 수많은 연구가 진행되었다. 이중 Night-to-Day image translation은 이를 해결하기 위한 포괄적인 해결책을 제공한다. 따라서 Image translation에서의 목표는 주간이미지로 변환하면서 semantic 정보를 잘 유지하는 것인데, Ground truth가 존재하지 않고, 복잡한 degradation으로 인해 작업에 어려움이 존재한다.

&nbsp;&nbsp;이를 해결하기 위해서 이전의 연구들은 Cycle-Consistent Learning이나, Domain-invariant learning 방법을 사용하였다. 이 방법들은 주로 GAN 기반의 모델들인데, Semantic structure에서의 약점이 있어 artifact가 발생하는 한계점이 존재하였다. 이외에도 Uncertainty를 도입한 **AUGAN**, GPS를 사용한 여러 방법이 존재했지만 여전히 artifact가 발생하였다. 또한 최근에는 Segmentation map이나 bounding box를 사용하여 작업하려는 전략도 존재했지만 cost가 많이 발생하여 한계가 있었다.

&nbsp;&nbsp; 논문은 여기에서 **Physcial prior를 사용하면 효율적인 방법이 되지 않을까?**라는 의문을 가져 **물리적적 관점에서 Night-Domain에서 domain invariant feature를 정의하였다.** 특히, 균일한 에너지를 자지지만, 고르지 않은 조명에서의 reflection은 Domain invariant region이라고 부르는 **well-lit**영역에 해당한다. well-lit region은 일반적으로 야간 이미지에서 중간 정도의 조명 세기를 의미하며, normal condition에서 강한 반사를 일으키지 않는 조명 영역이다.

![Image5](/assets/images/N2D3/image1.jpg){: .align-center}

&nbsp;&nbsp; 위 그림처럼 논문에서는 image 영역을 **High-light, Darkness, Well-lit, Light Effects**로 나누는데, colored illumination은 domain-specific임에도 불구하고, well-lit과 유사한 조명 강도를 가진다. 따라서 well-lit과 light effect를 구분해야하는 것이 핵심이다. 이를 구분하기 위해서 논문에서는 아래와 같이 두 가지 모듈로 모델을 구성하여 처리한다. N2D3는 GAN을 활용하여 야간과 주간 domain의 차이를 degradation-aware 방법을 통해 줄여나간다.

1. physics-informed degradation disentanglement

2. degradation-aware contrastive learning

&nbsp;&nbsp; 이 두 모듈은 모두 야간 이미지의 의미 구조를 보존하는 것을 목표로 한다.

![Image5](/assets/images/N2D3/image2.jpg){: .align-center}

&nbsp;&nbsp;  night degradation disentanglement를 위해서, 논문에서는 맞춤화된 **photometric model(광도 모델)**을 통해서 physics-prior를 추출한다. 이후 다양한 패턴을 분리하는데, 조명 강도를 기준으로서로 겹치지 않는 영역으로 구분한다.

    1. high-light
    2. well-lit
    3. darkness

&nbsp;&nbsp;또한 well-lit으로 부터 light effects를 분리하기 위해 color invariance 특성을 사용하는데 이것은 light effects를 분리하는 데 효과적이라는 것을 증명한다.

&nbsp;&nbsp;이를 기반으로 하여 degradation-aware contrastive learning은 서로 다른 영영ㄱ에서 원본 이미지와 생성 이미지의 유사성을 제약하도록 설계된다. 이 것은 두 가지 전략으로 구성된다.

* disentanglement-guided sampling
* reweighting strategy

&nbsp;&nbsp; 샘플링 전략은 anchor 및 hard negatives를 찾아내고, reweighting은 이에 대한 가중치를 할당한다. 이는 기존 학습보다 가치있는 패치에 attention을 부여함으로써 성능을 향상시킨다.

&nbsp;&nbsp; 논문에서의 기여를 요약하면 다음과 같다.

1. image degradation disentanglement module에 기반한 N2D3 변환 방법을 제안하며, 이는 degradation-aware contrastive learning 기반의 야간 이미지 복원을 가능하게 한다.

2. 새로운 degradation-aware contrastive learning 모듈을 제안하며, 생성된 결과물의 의미 구조를 보존한다. 핵심 설계는 ㅇㅇisentanglement-guided sampling과 reweighting strategy을 통합하여, 기존 대비 학습 성능을 크게 향상시킨다.

3. 두 개의 공개 데이터셋에서 수행된 실험 결과는, 야간 장면에서 다양한 degradation type을 고려하는 것의 중요성을 강조하며, 우리의 방법이 시각적 효과와 후속 작업 성능 모두에서 최첨단(state-of-the-art) 성능을 달성했음을 보여준다.

