---
layout: single
title: "Night-to-Day Translation via Illumination Degradation Disentanglement(N2D3, 2024)"


excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-04-21
last_modified_at: 2025-04-21
classes: #wide    
---
[Night-to-Day Translation via Illumination Degradation Disentanglement](https://arxiv.org/pdf/2411.14504){: .btn .btn--primary}


# Abstract

&nbsp;&nbsp;Night to Day translation은 야간 이미지를 주간 이미지로 바꾸는 것에 초점을 둔다. 기존의 변환 방법에서는 semantic 정보를 보존하면서, day-domain 정보를 복원하였는데, 이 것은 degradation이 다른 pixel과 균일하게 완화되기 때문에, 성능을 향상시키는데 부적절하다는 것이 입증 되었다. 

&nbsp;&nbsp;따라서 논문에서는 **N2D3(Night-to-Day via Degradation Disentanglement)**방법을 제안한다. 이방법은 degradation pattern을 식별하기 위해 **Degradation disentanglement module**과 **Degradation-aware contrastive learning module**로 구성된다. 

&nbsp;&nbsp;이 것은 **Kubelka-Munk Theory**에 기반하여 photometic model로 부터 physical priors를 추출하고, illumination degradation regions을 구분하기 위해 disentanglement module을 설계한다. 이후 degradation-aware contrastive learning 전략을 사용하여, 서로 다른 degradation region에 대해 semantic consistency를 유지한다.

# 1. Introduction

&nbsp;&nbsp;야간 이미지는 Computer vision에서 탐지하기 어려운 경향이 있으며, 이에 관련하여 수많은 연구가 진행되었다. 이중 Night-to-Day image translation은 이를 해결하기 위한 포괄적인 해결책을 제공한다. 따라서 Image translation에서의 목표는 주간이미지로 변환하면서 semantic 정보를 잘 유지하는 것인데, Ground truth가 존재하지 않고, 복잡한 degradation으로 인해 작업에 어려움이 존재한다.

&nbsp;&nbsp;이를 해결하기 위해서 이전의 연구들은 Cycle-Consistent Learning이나, Domain-invariant learning 방법을 사용하였다. 이 방법들은 주로 GAN 기반의 모델들인데, Semantic structure에서의 약점이 있어 artifact가 발생하는 한계점이 존재하였다. 이외에도 Uncertainty를 도입한 **AUGAN**, GPS를 사용한 여러 방법이 존재했지만 여전히 artifact가 발생하였다. 또한 최근에는 Segmentation map이나 bounding box를 사용하여 작업하려는 전략도 존재했지만 cost가 많이 발생하여 한계가 있었다.

&nbsp;&nbsp; 논문은 여기에서 **Physcial prior를 사용하면 효율적인 방법이 되지 않을까?**라는 의문을 가져 **물리적적 관점에서 Night-Domain에서 domain invariant feature를 정의하였다.** 특히, 균일한 에너지를 자지지만, 고르지 않은 조명에서의 reflection은 Domain invariant region이라고 부르는 **well-lit**영역에 해당한다. well-lit region은 일반적으로 야간 이미지에서 중간 정도의 조명 세기를 의미하며, normal condition에서 강한 반사를 일으키지 않는 조명 영역이다.

![Image5](/assets/images/N2D3/image1.jpg){: .align-center}

&nbsp;&nbsp; 위 그림처럼 논문에서는 image 영역을 **High-light, Darkness, Well-lit, Light Effects**로 나누는데, colored illumination은 domain-specific임에도 불구하고, well-lit과 유사한 조명 강도를 가진다. 따라서 well-lit과 light effect를 구분해야하는 것이 핵심이다. 이를 구분하기 위해서 논문에서는 아래와 같이 두 가지 모듈로 모델을 구성하여 처리한다. N2D3는 GAN을 활용하여 야간과 주간 domain의 차이를 degradation-aware 방법을 통해 줄여나간다.

1. physics-informed degradation disentanglement

2. degradation-aware contrastive learning

&nbsp;&nbsp; 이 두 모듈은 모두 야간 이미지의 의미 구조를 보존하는 것을 목표로 한다.

![Image5](/assets/images/N2D3/image2.jpg){: .align-center}

&nbsp;&nbsp;  night degradation disentanglement를 위해서, 논문에서는 맞춤화된 **photometric model(광도 모델)**을 통해서 physics-prior를 추출한다. 이후 다양한 패턴을 분리하는데, 조명 강도를 기준으로서로 겹치지 않는 영역으로 구분한다.

    1. high-light
    2. well-lit
    3. darkness

&nbsp;&nbsp;또한 well-lit으로 부터 light effects를 분리하기 위해 color invariance 특성을 사용하는데 이것은 light effects를 분리하는 데 효과적이라는 것을 증명한다.

&nbsp;&nbsp;이를 기반으로 하여 degradation-aware contrastive learning은 서로 다른 영영ㄱ에서 원본 이미지와 생성 이미지의 유사성을 제약하도록 설계된다. 이 것은 두 가지 전략으로 구성된다.

* disentanglement-guided sampling
* reweighting strategy

&nbsp;&nbsp; 샘플링 전략은 anchor 및 hard negatives를 찾아내고, reweighting은 이에 대한 가중치를 할당한다. 이는 기존 학습보다 가치있는 패치에 attention을 부여함으로써 성능을 향상시킨다.

&nbsp;&nbsp; 논문에서의 기여를 요약하면 다음과 같다.

1. image degradation disentanglement module에 기반한 N2D3 변환 방법을 제안하며, 이는 degradation-aware contrastive learning 기반의 야간 이미지 복원을 가능하게 한다.

2. 새로운 degradation-aware contrastive learning 모듈을 제안하며, 생성된 결과물의 의미 구조를 보존한다. 핵심 설계는 ㅇㅇisentanglement-guided sampling과 reweighting strategy을 통합하여, 기존 대비 학습 성능을 크게 향상시킨다.

3. 두 개의 공개 데이터셋에서 수행된 실험 결과는, 야간 장면에서 다양한 degradation type을 고려하는 것의 중요성을 강조하며, 우리의 방법이 시각적 효과와 후속 작업 성능 모두에서 최첨단(state-of-the-art) 성능을 달성했음을 보여준다.

# 2. Related work

1. Unpaired Image-to-Image Translation

2. Nighttime Domain Translation

# 3. Method

### Define:

- **Night Image**: $ I_{\mathcal{N}} \in \mathcal{N} $
- **Day Image**: $ I_{\mathcal{D}} \in \mathcal{D} $

Night2Day의 목표는 Semantic consistency를 유지하면서 야간 이미지를 주간 이미지로 변환하는 것이다.

---

### mapping function:

야간에서 주간으로의 변환을 위한 mapping function $\mathcal{F}$는 다음과 같이 정의된다:

$$
\mathcal{F}_\theta : I_{\mathcal{N}} \rightarrow I_{\mathcal{D}}
$$

- $\theta $: parameter
- $\mathcal{F}_\theta$ : trained model

---

### Framework:

- Night2Day translator를 학습하기 위해 Framework로 **GANs** 사용

- 핵심 설계 요소:
  - **Degradation Disentanglement Module**
  - **Degradation-Aware Contrastive Learning Module**

이 두 모듈은 원본 이미지의 **구조 정보 보존**하고, 변환 중 발생 가능한 **artifect를 억제**하는 역할을 한다.

## 3.1 Physical Priors for Nighttime Environment

야간에서의 illumination degradation은 아래 그림처럼 주로 4가지 타입으로 구성된다.

![Image5](/assets/images/N2D3/image3.jpg){: .align-center}

1. darkness
2. well-lit regions
3. high-llight regions
4. light effects

&nbsp;&nbsp; **well-lit**은 normal한 조명 하에서 diffused reflectance(확산 반사) 성분을 의미하고, light effect는 flare, glow, specular reflection 등과 같은 현상을 의미한다. 직관적으로 이 region들은 illumination distribution을 분석하여 분리할 수 있다. 이러한 degradation types 중 darkness와 high light는 조명 강도와 직접적인 상관관계를 가지며, illumination estimation을 통해서 효과적으로 분리할 수 있다.

&nbsp;&nbsp; 일반적인 방법으로는 night image $ I_{\mathcal{N}}$의 RGB 채널 중 최대값을 활용하여 illuminance map $L$을 추정한다

$$L = max_{c\in{R,G,B}}I_{\mathcal{N}}^c$$

이 후 k-means를 통해 darkness, well-lit, high-light를 나타내는 세 개의 cluster를 얻어낸다. 이 cluster들은 mask $M_d, M_n, M_h$로 표현된다. 

&nbsp;&nbsp; 그러나 여기에서의 문제는 light effect에서 발생한다. Light effects regions은 종종 well-lit region과 유사한 조도를 사용하여 illuminance map으로만 분리하는데는 어려움이 있다. 이를 해결하기 위해 **physical priors**를 도입한다.

### Physical priors

&nbsp;&nbsp; light effects를 분리하기 위한 physical prior를 추출하기 위해, 논문에서는 **Kubelka-Munk Theory**에 기반한 광도 모델(Photometric model)을 개발한다. 이 모델은 물체에서 반사되는 빛의 스펙트럼을 $E$로 나타낸다.

$$
E(\lambda, x) = e(\lambda, x)(1 - \rho_f(x))^2 R_{\infty}(\lambda, x) + e(\lambda, x) \rho_f(x) \tag{1}
$$

- $ x $: 수평 위치
- $ \lambda $: 파장
- $ e(\lambda, x) $: 입사광 스펙트럼
- $ \rho_f(x) $: 프레넬 반사 계수 (Fresnel reflectance coefficient)
- $ R_\infty(\lambda, x) $: 무한 두께에서의 반사율

materials이 **uniformity and homogeneity(균일하고 동질적)**이라는 가정 하에,   반사율 함수는 다음과 같이 분리될 수 있다:

$$
R_\infty(\lambda, x) = R(\lambda)C(x) \tag{2}
$$

- $ R(\lambda) $: 파장에 따른 반사 특성
- $ C(x) $: 공간적 물질 분포 함수 (재질 계수들로 구성)

light effect region과 well-lit region은 **비슷한 조명 밀도**를 가지므로, 분리의 핵심은 다음 두 성분을 나누는 것에 있다:

- 입사광 $ e(\lambda, x) $
- 반사율 $ R(\lambda)C(x) $

---

따라서 식 (1)에 따라 **light effect region과 well-lit region**의 스펙트럼 모델은 다음과 같다:

$$
E(\lambda, x) =
\begin{cases}
e(\lambda, x), & x \in \Omega \\
e(\lambda, x)R(\lambda)C(x), & x \notin \Omega
\end{cases} \tag{3}
$$

- $ \Omega $: 광원 효과가 지배적인 영역

---

* Corollary 1 – color invariant

uniformity and homogeneity 가정 하에, illumination 스펙트럼의 **완전하고 축소 불가능한 불변량(invariant)**은 다음과 같다:

$$
N_{\lambda^m x^n} =
\begin{cases}
\frac{\partial^{m+n-1}}{\partial \lambda^{m-1} \partial x^{n-1}} \left( \frac{1}{E(\lambda, x)} \cdot \frac{\partial E(\lambda, x)}{\partial \lambda} \right), \\
\frac{\partial^{m+n-1}}{\partial \lambda^{m-1} \partial x^{n-1}} \left( \frac{1}{E(\lambda, x)} \cdot \frac{\partial e(\lambda, x)}{\partial \lambda} \right)
\end{cases} \tag{4}
$$

---

이 invariants $ N_{\lambda^m x^n} $은 조명과 관련된 특성만 포착하며, light effect detector로 작동할 수 있다.

## 3.2 Degradation Disentanglement Module

&nbsp;&nbsp;여기에서는 computation을 통해 light effect를 추출하는 방법을 설명한다. 일반적으로 horizontal, vertical 방향에서 2,3번째 차수의 component를 포함시켜 최종 invariant를 계산하는데 사용한다. 이 invariant는 $N$으로 정의된다.  

$$
N = \sqrt{N_{x\lambda}^2 + N_{\lambda x}^2 + N_{xy}^2 + N_{\lambda xy}^2} \tag{5}
$$

여기에서 $N_{x\lambda}$와 $N_{\lambda x}$는 식 (4)를 단순화 햐여 **$E(\lambda,x)$**로 계산할 수 있다.



$$
N_{x\lambda} = \frac{E_x E - E_\lambda E_x}{E^2}, \quad
N_{\lambda \lambda x} = \frac{E_{\lambda \lambda x} E - E_{\lambda \lambda} E_x - 2 E_{\lambda x} E_\lambda E + 2 E_\lambda^2 E_x}{E^3} \tag{6}
$$


1. **E 및 편미분 계산**:

$$
E(x, y), E_x(x, y), E_\lambda(x, y)
$$

2. **가우시안 커널을 활용한 x방향 편미분**:

$$
E_x(x, y, \sigma) = \sum_{t \in \mathcal{Z}} E(t, y) \cdot \frac{\partial g(x - t, \sigma)}{\partial x} \tag{8}
$$

3. **불변량 \( N \) 정제**:

$$
M_{le} = ReLU( (N - μ(N)) / σ(N) ) ⊙ M_n
$$