---
layout: single
title: "Night-to-Day Translation via Illumination Degradation Disentanglement(N2D3, 2024)"


excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-04-21
last_modified_at: 2025-04-21
classes: #wide    
---
[Night-to-Day Translation via Illumination Degradation Disentanglement](https://arxiv.org/pdf/2411.14504){: .btn .btn--primary}


# Abstract

&nbsp;&nbsp;Night to Day translation은 야간 이미지를 주간 이미지로 바꾸는 것에 초점을 둔다. 기존의 변환 방법에서는 semantic 정보를 보존하면서, day-domain 정보를 복원하였는데, 이 것은 degradation이 다른 pixel과 균일하게 완화되기 때문에, 성능을 향상시키는데 부적절하다는 것이 입증 되었다. 

&nbsp;&nbsp;따라서 논문에서는 **N2D3(Night-to-Day via Degradation Disentanglement)**방법을 제안한다. 이방법은 degradation pattern을 식별하기 위해 **Degradation disentanglement module**과 **Degradation-aware contrastive learning module**로 구성된다. 

&nbsp;&nbsp;이 것은 **Kubelka-Munk Theory**에 기반하여 photometic model로 부터 physical priors를 추출하고, illumination degradation regions을 구분하기 위해 disentanglement module을 설계한다. 이후 degradation-aware contrastive learning 전략을 사용하여, 서로 다른 degradation region에 대해 semantic consistency를 유지한다.

# 1. Introduction

&nbsp;&nbsp;야간 이미지는 Computer vision에서 탐지하기 어려운 경향이 있으며, 이에 관련하여 수많은 연구가 진행되었다. 이중 Night-to-Day image translation은 이를 해결하기 위한 포괄적인 해결책을 제공한다. 따라서 Image translation에서의 목표는 주간이미지로 변환하면서 semantic 정보를 잘 유지하는 것인데, Ground truth가 존재하지 않고, 복잡한 degradation으로 인해 작업에 어려움이 존재한다.

&nbsp;&nbsp;이를 해결하기 위해서 이전의 연구들은 Cycle-Consistent Learning이나, Domain-invariant learning 방법을 사용하였다. 이 방법들은 주로 GAN 기반의 모델들인데, Semantic structure에서의 약점이 있어 artifact가 발생하는 한계점이 존재하였다. 이외에도 Uncertainty를 도입한 **AUGAN**, GPS를 사용한 여러 방법이 존재했지만 여전히 artifact가 발생하였다. 또한 최근에는 Segmentation map이나 bounding box를 사용하여 작업하려는 전략도 존재했지만 cost가 많이 발생하여 한계가 있었다.

&nbsp;&nbsp; 논문은 여기에서 **Physcial prior를 사용하면 효율적인 방법이 되지 않을까?**라는 의문을 가져 **물리적적 관점에서 Night-Domain에서 domain invariant feature를 정의하였다.** 특히, 균일한 에너지를 자지지만, 고르지 않은 조명에서의 reflection은 Domain invariant region이라고 부르는 **well-lit**영역에 해당한다. well-lit region은 일반적으로 야간 이미지에서 중간 정도의 조명 세기를 의미하며, normal condition에서 강한 반사를 일으키지 않는 조명 영역이다.

![Image5](/assets/images/N2D3/image1.jpg){: .align-center}

&nbsp;&nbsp; 위 그림처럼 논문에서는 image 영역을 **High-light, Darkness, Well-lit, Light Effects**로 나누는데, colored illumination은 domain-specific임에도 불구하고, well-lit과 유사한 조명 강도를 가진다. 따라서 well-lit과 light effect를 구분해야하는 것이 핵심이다. 이를 구분하기 위해서 논문에서는 아래와 같이 두 가지 모듈로 모델을 구성하여 처리한다. N2D3는 GAN을 활용하여 야간과 주간 domain의 차이를 degradation-aware 방법을 통해 줄여나간다.

1. physics-informed degradation disentanglement

2. degradation-aware contrastive learning

이 두 모듈은 모두 야간 이미지의 의미 구조를 보존하는 것을 목표로 한다.

![Image5](/assets/images/N2D3/image2.jpg){: .align-center}

