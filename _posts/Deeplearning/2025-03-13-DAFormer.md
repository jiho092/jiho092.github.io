---
layout: single
title: "DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation"


excerpt : ""
categories: 
    - deeplearningCV #카테고리설정
tag: 
    - [] #테그

date: 2025-03-13
last_modified_at: 2025-03-13
classes: #wide    
---
[DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation](https://arxiv.org/pdf/2111.14887){: .btn .btn--primary}

# Abstract

&nbsp;&nbsp; 이미지의 semantic segmentation을 위해서 pixel 단위의 annotation을 수집하는 것은 비용이 많이 든다. 비용 문제를 해결하기 위해 systhetic data를 통해 모델을 학습한 후 real image로 adaptation하는 방법이 사용될 수 있다. 이것은 Unsupervised domain adaptation(UDA)라는 분야이다.

&nbsp;&nbsp; 기존의 많은 연구들이 새로운 adaptation 전략을 제안하고 있지만, 대부분 오래된 network architecture(CNN, DeepLab v2)를 사용하고 있다. 최근에 제안된 architecture의 영향을 체계적으로 연구한 적이 없기 때문에, 이 논문에서는 **UDA**를 위한 다양한 최신 Architecture를 벤치마킹하고, Transformer based network가 UDA segmentation에서 좋은 잠재력을 가진다는 것을 발견하였다.

&nbsp;&nbsp; 따라서 논문에서는 새로운 UDA 방법인 **DAformer**를 제안한다. 이 network는 Transformer Encoder와 Multi-level Context-aware Feature Fusion Decoder로 구성된다.

&nbsp;&nbsp; 또한 모델 학습을 안정화하고 source domain으로 부터 과적합 문제를 예방하기위해 세 가지 학습 전략을 사용하였다.

1. Rare Class Sampling

    - source domain에서 희귀한 class의 샘플을 증가시켜, self training의 corfirmation bias를 줄인다.
    - 이를 통해 pseudo-label의 품질을 향상 시킴

2. Thing-Class ImageNet Feature Distance

    - Thing Class(명확한 객체를 나타내는 clas : 차량, 사람)에 대한 특징을 ImageNet pre-trained model과 정렬하여 특징을 효과적으로 전달하도록 유도

3. Learning Rate Warmup

    - ImageNet pre-trained model의 특징 전달을 촉진하기 위해 학습 초기에 learning rate를 천천히 증가시키는 방법을 사용

&nbsp;&nbsp;  DAFormer는 UDA 분야에서 큰 성능 향상을 보였다. 특히, GTA $\to$ Cityscapes에서 기존 SOTA보다 10.8 mIoU가 향상되었고, Synthia $\to$ Cityscapes에서 5.4 mIoU 향상되었다. 또한 학습이 어려운 bus, truck과 같은 class에서도 높은 성능을 달성하였다.

# 1. Introduction

&nbsp;&nbsp; 딥러닝은 Computer vision에서 압도적인 성능을 보였지만, 많은 annotation data가 필요하다. 특히, segmentation에서는 image 하나의 annotation을 만드는데 1.5~3.3시간이 걸린다. 이를 해결하기 위한 한가지 방법은 Synthetic data를 사용하는 것인데, domain shift에 민감하고 생성 데이터에 결함이 있어 어려운 점이 있다. 이를 UDA 방법을 사용하여 해결한다.

&nbsp;&nbsp; 이전의 UDA 방법들은 DeepLabV2, FCN8s 등의 network architecture와 ResNet, VGG 등의 backborn을을 사용해왔다. 이 것들은 오래된 기법이기 때문에 최상의 성능을 내기 어렵다. 따라서 논문에서는 UDA가 미치는 영향을 정확히 분석하기 위해 진보된(Sophisticated) network를 사용하여 성능을 극대화 하는 방법을 연구했다. 그러나 최신 모델이 overfitting 등으로 인해 반드시 성능 향상을 이끄는 것은 아니기 때문에 UDA 환경에서 다양한 Semantic segmentation network를 선정하고 적절한 학습 전략을 선택한다. 이러한 연구를 통해 **DAFormer**를 제안한다.

&nbsp;&nbsp; 더 복잡하고 강력한 architecture는 adaptation 불안정성과 source domain에 대한 overfitting에 취약할 수 있다. 이를 위해 새로운 세 가지 학습 전략을 도입한다.

## 1. Rare Class Sampling(RCS)

- source domain에서 잘 등장하지 않는 rare class의 학습을 개선
- self training 과정에서 일반적인 class의 confirmation bias 완화
- rare class가 포함된 이미지를 더 자주 sampling하여 pseudo-label 품질 향상 및 안정화

## 2. Thing-Class ImageNet Feature Distance(FD)

- 다양한 표현을 가진 ImageNet의 특징을 통해 source domain의 학습을 정규화
- source domain의 데이터의 다양성 문제와 domain shift로 발생하는 문제를 해결
- 